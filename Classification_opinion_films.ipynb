{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666c5f8f",
   "metadata": {},
   "source": [
    "---\n",
    "## **PROJET TAL** : Classification d'opinion de revues de films\n",
    "#### **Auteurs** : Matéo PETITET, Mélodie FLEURY \n",
    "#### **Matière** : UE TAL - Vincent GUIGUE - 3A IODAA AgroParisTech\n",
    "#### **Date de rendue** : 12 février 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a7f919",
   "metadata": {},
   "source": [
    "### Objectifs\n",
    "<span style=\"color:red\">(A REFORMULER UN PEU) </span>\n",
    "Le but de ce projet est d'utiliser des commentaires de films, en anglais, issus de l'Internet Movie Database (IMDb), une base de données en ligne dédiée à l'audiovisuel. Ces commentaires sont soit positifs soit négatifs par rapport au film dont ils parlent ; l'objectif est de déterminer, par différentes méthodes d'apprentissage machine, si la revue analysée est positive ou négative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d56c1c",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aed4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports des bibliothèques nécessaires\n",
    "\n",
    "import gc\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import ollama\n",
    "import optuna\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef965d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration des devices : permet d'accélérer matériellement les calculs sous cuda ou apple silicon\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "#Fixation de la graine aléatoire pour la reproductibilité des résultats\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "sampler = optuna.samplers.TPESampler(seed=seed)\n",
    "\n",
    "#Localisation des données utiles\n",
    "DATASET_PATH_TRAIN = Path(\"data/aclImdb/aclImdb/train\")\n",
    "DATASET_PATH_TEST = Path(\"data/aclImdb/aclImdb/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b32f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "\n",
    "global_result=[]\n",
    "global_methode=[]\n",
    "NB_DOC_MAX = 1000 # par classe\n",
    "IMDB_CLASSES  = ['neg','pos']\n",
    "VOC_SIZE = 10000\n",
    "BATCH_SIZE = 32\n",
    "MAX_CHAR_SIZE = 1000\n",
    "\n",
    "labels = dict(zip(IMDB_CLASSES,[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35514749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement des données\n",
    "\n",
    "def load_data(datapath, classes, max_size=None):\n",
    "    txts = []\n",
    "    files = []\n",
    "    filelabels = []\n",
    "    for label in classes:\n",
    "        c = 0\n",
    "        new = [os.path.join(datapath / label, f) for f in os.listdir(datapath / label) if f.endswith(\".txt\")]\n",
    "        files += new\n",
    "        # filelabels += [labels[label]] * len(new) \n",
    "        for file in (datapath / label).glob(\"*.txt\"):\n",
    "            t = file.read_text(encoding='utf8')\n",
    "            txts.append(t if len(t)<MAX_CHAR_SIZE else t[:MAX_CHAR_SIZE])\n",
    "            filelabels.append(labels[label])\n",
    "            c+=1\n",
    "            if max_size !=None and c>=max_size: break\n",
    "\n",
    "    return txts, files, filelabels\n",
    "\n",
    "txts, files, filelabels = load_data(DATASET_PATH_TRAIN, IMDB_CLASSES, max_size = NB_DOC_MAX)\n",
    "txts_test, files_test, filelabels_test = load_data(DATASET_PATH_TEST, IMDB_CLASSES, max_size = NB_DOC_MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522a296",
   "metadata": {},
   "source": [
    "### Première approche : apprentissage machine simple\n",
    "Effectuons une première classification naïve avec 3 régresseurs standards. Cela nous permettra d'établir une performance de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1facbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données pour les classificateurs : pas de prétraitement\n",
    "classes = filelabels\n",
    "corpus = txts\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Naïve Bayes\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X, classes)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)\n",
    "lr_clf.fit(X, classes)\n",
    "\n",
    "# Linear SVM\n",
    "svm_clf = LinearSVC(random_state=0, tol=1e-5, max_iter=1000)\n",
    "svm_clf.fit(X, classes)\n",
    "\n",
    "# Préparation des données de test\n",
    "true = filelabels_test\n",
    "test_corpus = txts_test\n",
    "X_test = vectorizer.transform(test_corpus)\n",
    "\n",
    "# Prédictions\n",
    "pred_nb = nb_clf.predict(X_test)\n",
    "global_result.append(accuracy_score(true, pred_nb)*100)\n",
    "global_methode.append('Naïve Bayes')\n",
    "pred_lr = lr_clf.predict(X_test)\n",
    "global_result.append(accuracy_score(true, pred_lr)*100)\n",
    "global_methode.append('Logistic Regression')\n",
    "pred_svm = svm_clf.predict(X_test)\n",
    "global_result.append(accuracy_score(true, pred_svm)*100)\n",
    "global_methode.append('SVM accuracy')\n",
    "\n",
    "# Évaluation\n",
    "print(f\"Naïve Bayes accuracy: {accuracy_score(true, pred_nb)*100}%\")\n",
    "print(f\"Logistic Regression accuracy: {accuracy_score(true, pred_lr)*100}%\")\n",
    "print(f\"SVM accuracy: {accuracy_score(true, pred_svm)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96d975",
   "metadata": {},
   "source": [
    "Ces scores nous donnent une première base de performances. Nous pouvons voir que nous avons dores et déjà des performances d'accuracy très bonnes à l'aide d'un <b>classifieur Bayésien naïf</b>.\n",
    "\n",
    "### L'approche \"Sac de Mots\"\n",
    "\n",
    "L'approche <b>\"Sac de Mots\"</b> (\"Bag of Words\", BoW) consiste en la représentation d'un texte par un vecteur de la même taille que le vocabulaire du texte. Cette approche est simpliste et ne prend pas en compte le contexte, mais peut permettre d'obtenir tout de même des résultats intéressants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59803ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Méthode Bag of Words\n",
    "X_train = vectorizer.fit_transform(txts).toarray()\n",
    "X_test = vectorizer.transform(txts_test).toarray()\n",
    "vocab_size = X_train.shape[1]\n",
    "\n",
    "# Conversion des labels en tenseurs PyTorch\n",
    "y_train = torch.tensor(filelabels, dtype=torch.long)\n",
    "y_test = torch.tensor(filelabels_test, dtype=torch.long)\n",
    "\n",
    "# Conversion des données en tenseurs PyTorch\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# Définition du modèle\n",
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(vocab_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialisation du modèle\n",
    "num_classes = 2  # Positif ou négatif\n",
    "model = BoWClassifier(vocab_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b360a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Entraînement et performances\n",
    "\n",
    "# Liste pour stocker les valeurs de loss et accuracy\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Évaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        test_loss = criterion(outputs, y_test).item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "    train_losses.append(loss.item())\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc53cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé des courbes\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Courbe de la loss\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.plot(train_losses, label='Train Loss', color='blue')\n",
    "ax1.plot(test_losses, label='Test Loss', color='orange')\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Courbe de l'accuracy\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.plot(test_accuracies, label='Test Accuracy', color='green')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Légende et affichage\n",
    "fig.tight_layout()\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.title('Training Loss and Test Accuracy')\n",
    "plt.show()\n",
    "\n",
    "print('Meilleure accuracy : ', max(test_accuracies), '%')\n",
    "global_result.append(max(test_accuracies))\n",
    "global_methode.append('Bag of Words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faa5768",
   "metadata": {},
   "source": [
    "![Training Loss et Test Accuracy](images/bow.png)\n",
    "Nous pouvons constater que la meilleure accuracy atteinte, bien que relativement bonne, n'égale pas celle du classifieur Bayésien naïf. De plus, nous observons la chute des performance avec le nombre d'epochs de 'entraînement ; un sur-apprentissage a lieu.\n",
    "\n",
    "L'un des inconvénient du BoW est qu'il va, par défaut, distinguer des mots selon leurs majuscules, accents... Et ainsi mener à une taille de vocabulaire bien plus importante et une perte de performance. Pour éviter cela, nous allons appliquer différents prétraitements :\n",
    "- conversion intégrale du texte en minuscule\n",
    "- suppression des nombres (ici peut utiles a priori)\n",
    "- suppression des ponctuations (sans utiliser le contexte elles sont également inutiles)\n",
    "- utilisation de \"stopwords\", mots volontairement ignorés ; une liste est directement importée\n",
    "- lemmatisation, ramener les mots à leur forme de base\n",
    "- tokenisation\n",
    "\n",
    "Toutes ces procédures permettent de simplifier grandement le vocabulaire de représentation et possiblement d'améliorer les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prétraitement\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Conversion en minuscules\n",
    "    text = text.lower()\n",
    "\n",
    "    # Suppression des nombres\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Suppression des ponctuations\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Suppression des stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Rejoindre les tokens en une chaîne\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données avec prétraitement\n",
    "def load_data(datapath, classes, max_size=None):\n",
    "    txts = []\n",
    "    files = []\n",
    "    filelabels = []\n",
    "    for label in classes:\n",
    "        c = 0\n",
    "        new = [os.path.join(datapath / label, f) for f in os.listdir(datapath / label) if f.endswith(\".txt\")]\n",
    "        files += new\n",
    "        for file in (datapath / label).glob(\"*.txt\"):\n",
    "            t = file.read_text(encoding='utf8')\n",
    "            t = preprocess_text(t)  # Appliquer le prétraitement\n",
    "            txts.append(t if len(t) < MAX_CHAR_SIZE else t[:MAX_CHAR_SIZE])\n",
    "            filelabels.append(labels[label])\n",
    "            c += 1\n",
    "            if max_size is not None and c >= max_size:\n",
    "                break\n",
    "    return txts, files, filelabels\n",
    "\n",
    "# Chargement des données\n",
    "txts, files, filelabels = load_data(DATASET_PATH_TRAIN, IMDB_CLASSES, max_size=NB_DOC_MAX)\n",
    "txts_test, files_test, filelabels_test = load_data(DATASET_PATH_TEST, IMDB_CLASSES, max_size=NB_DOC_MAX)\n",
    "\n",
    "# Méthode Bag of Words\n",
    "X_train = vectorizer.fit_transform(txts).toarray()\n",
    "X_test = vectorizer.transform(txts_test).toarray()\n",
    "vocab_size = X_train.shape[1]\n",
    "\n",
    "# Conversion des labels en tenseurs PyTorch\n",
    "y_train = torch.tensor(filelabels, dtype=torch.long)\n",
    "y_test = torch.tensor(filelabels_test, dtype=torch.long)\n",
    "\n",
    "# Conversion des données en tenseurs PyTorch\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# Définition du modèle\n",
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes):\n",
    "        super(BoWClassifier, self).__init__()\n",
    "        self.fc = nn.Linear(vocab_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialisation du modèle\n",
    "num_classes = 2  # Positif ou négatif\n",
    "model = BoWClassifier(vocab_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Entraînement et performances\n",
    "# Liste pour stocker les valeurs de loss et accuracy\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Évaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        test_loss = criterion(outputs, y_test).item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "    train_losses.append(loss.item())\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(accuracy*100)\n",
    "\n",
    "# Tracé des courbes\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Courbe de la loss\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.plot(train_losses, label='Train Loss', color='blue')\n",
    "ax1.plot(test_losses, label='Test Loss', color='orange')\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Courbe de l'accuracy\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.plot(test_accuracies, label='Test Accuracy', color='green')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Légende et affichage\n",
    "fig.tight_layout()\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.title('Training Loss and Test Accuracy - Prétraitements')\n",
    "plt.show()\n",
    "\n",
    "print('Meilleure accuracy : ', max(test_accuracies), '%')\n",
    "\n",
    "global_result.append(max(test_accuracies))\n",
    "global_methode.append('Bag of Words - Prétraitements')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866ee320",
   "metadata": {},
   "source": [
    "![Training Loss et Test Accuracy - Prétraitement](images/bow-pt.png)\n",
    "Les performances s'améliorent ici par rapport au BoW brut, et parviennent même à dépasser celles du classifieur Bayésien naïf. Toutefois, cette deuxième \"victoire\" n'est, contrairement à la première, pas systématique.\n",
    "\n",
    "Afin d'améliorer encore les performances de cette approche, nous pouvons lancer une campagne de recherche des meilleurs hyperparamètres. Avec notre fonction BoW simple, nous pouvons jouer sur :\n",
    "- le taux d'apprentissage\n",
    "- la taille du batch\n",
    "- le nombre d'epochs\n",
    "- la taille des n-grammes\n",
    "\n",
    "Les n-grammes correspondent à la taille des sacs de mots considérés. Un \"mot\" de vocabulaire peut être ainsi constitué de deux mots réels, et donner une forme de contexte. Dans notre cas, si un commentaire négatif contient \"not good\", une aproche uniquement par unigrammes pourra interpréter la présence du \"good\" comme signe d'un commentaire positif, alors qu'une approche bigramme considèrera le \"not good\" entier et tendra plus vers une classification en négatif.\n",
    "\n",
    "Afin de mener cette campagne d'optimisation, nous utilisons Optuna, très performant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11071dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'objectif pour Optuna\n",
    "def objective(trial):\n",
    "    # Suggestion des hyperparamètres\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "    num_epochs = trial.suggest_int('num_epochs', 10, 100)\n",
    "    ngram_range = trial.suggest_categorical('ngram_range', [(1, 1), (1, 2), (1, 3), (2, 2), (2, 3)])\n",
    "\n",
    "    # Initialisation du modèle et de l'optimiseur\n",
    "    model = BoWClassifier(vocab_size, num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # DataLoader avec la taille de batch spécifiée\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Entraînement et évaluation\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Évaluation sur l'ensemble de test\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test)\n",
    "            test_loss = criterion(test_outputs, y_test).item()\n",
    "            _, predicted = torch.max(test_outputs, 1)\n",
    "            accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "\n",
    "        # Report de l'accuracy à Optuna\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Préparation pour l'early stopping\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Création de l'étude Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "global_result.append(format(trial.value)*100)\n",
    "global_methode.append('Bag of Words - Prétraitements - Optimisé')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822279fa",
   "metadata": {},
   "source": [
    "Best trial:\n",
    "\n",
    "    Value: 0.83\n",
    "  \n",
    "  Params: \n",
    "  \n",
    "    learning_rate: 0.0006832210867221183  \n",
    "    batch_size: 16\n",
    "    num_epochs: 45\n",
    "    ngram_range: (1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161f9689",
   "metadata": {},
   "source": [
    "La campagne a permis de trouver de nouveaux hyperparamètres améliorants encore la performance du BoW. Nous sommes ainsi clairement au-dessus du classifieur Bayésien naïf. Toutefois, ces approches restent dans un cadre d'apprentissage machine classique. Essayons à présent une approche en apprentissage profond.\n",
    "\n",
    "### L'approche apprentissage profond\n",
    "\n",
    "Nous allons utiliser une représentation des mots (embeddings) déjà fournie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f7ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nouveau chargement des données\n",
    "\n",
    "GLOVE_PATH = Path(\"data/glove/glove\") # données non fournies dans Github (/!\\ place mémoire)\n",
    "DATASET_PATH = Path(\"data/aclImdb/aclImdb\")\n",
    "\n",
    "class FolderText(Dataset):\n",
    "    \"\"\"Dataset basé sur des dossiers (un par classe) et fichiers\"\"\"\n",
    "\n",
    "    def __init__(self, classes, folder: Path, tokenizer, train_max_size=None, load=False):\n",
    "        self.tokenizer = tokenizer   #Utilisation du tokenizer importé\n",
    "        self.files = []\n",
    "        self.filelabels = []\n",
    "        self.labels = {key: ix for ix, key in enumerate(classes)}\n",
    "        \n",
    "        for label in classes:\n",
    "            c = 0\n",
    "            for file in (folder / label).glob(\"*.txt\"):\n",
    "                self.files.append(file.read_text(encoding='utf8') if load else file)\n",
    "                self.filelabels.append(self.labels[label])\n",
    "                c += 1\n",
    "                if train_max_size is not None and c > train_max_size:\n",
    "                    break\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelabels)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        s = self.files[ix]\n",
    "        tokenized = torch.tensor(self.tokenizer(s if isinstance(s, str) else s.read_text()), device=device)\n",
    "        label = torch.tensor(self.filelabels[ix], device=device)\n",
    "        return tokenized, label\n",
    "\n",
    "def get_imdb_data(embedding_size=50, train_max_size=None):\n",
    "    \"\"\"Renvoie l'ensemble des données nécessaires pour l'apprentissage \n",
    "\n",
    "    - dictionnaire word vers ID\n",
    "    - embeddings (Glove)\n",
    "    - DataSet (FolderText)\n",
    "\n",
    "    \"\"\"\n",
    "    WORDS = re.compile(r\"\\S+\")\n",
    "    glove_fn = open(GLOVE_PATH / (\"glove.6B.%dd.txt\" % embedding_size), encoding='utf8')\n",
    "    words, embeddings = [], []\n",
    "    \n",
    "    for line in glove_fn:\n",
    "        values = line.split()\n",
    "        words.append(values[0])\n",
    "        embeddings.append([float(x) for x in values[1:]])\n",
    "\n",
    "    OOVID = len(words)\n",
    "    words.append(\"__OOV__\")\n",
    "\n",
    "    word2id = {word: ix for ix, word in enumerate(words)}\n",
    "    embeddings = np.vstack((embeddings, np.zeros(embedding_size)))\n",
    "    embeddings = torch.tensor(embeddings, dtype=torch.float32, device=device)\n",
    "\n",
    "    def tokenizer(t):\n",
    "        return [word2id.get(x, OOVID) for x in re.findall(WORDS, t.lower())]\n",
    "\n",
    "    logging.info(\"Loading embeddings\")\n",
    "    logging.info(\"Get the IMDB dataset\")\n",
    "    \n",
    "    return word2id, embeddings, FolderText(IMDB_CLASSES, DATASET_PATH / \"train\", tokenizer, train_max_size, load=True), FolderText(IMDB_CLASSES, DATASET_PATH / \"test\", tokenizer, train_max_size, load=True)\n",
    "\n",
    "word2id, embeddings, train_dataset, test_dataset = get_imdb_data()\n",
    "\n",
    "#data loader\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences], device=device)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=False).to(device)\n",
    "    labels = torch.tensor(labels, device=device)\n",
    "    return padded_sequences, torch.tensor(lengths), torch.tensor(labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du réseau\n",
    "class RNNSent(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, embeddings, device):\n",
    "        super(RNNSent, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = len(embeddings[0])\n",
    "        self.emb = nn.Embedding(len(embeddings), len(embeddings[0]))\n",
    "\n",
    "        # INITIALISATION des embeddings\n",
    "        self.emb.weight.requires_grad = False\n",
    "        \n",
    "        # Envoyer l'embedding layer sur le device\n",
    "        self.emb.to(device)\n",
    "\n",
    "        # CHOIX Du module récurrent\n",
    "        self.rec = nn.RNN(self.input_size, self.hidden_size, nonlinearity='tanh').to(device)\n",
    "\n",
    "        # ATTENTION\n",
    "        self.attention = nn.Linear(hidden_size, 1, bias=False).to(device)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size).to(device)\n",
    "\n",
    "        \n",
    "    def forward(self, input, lengths=None):\n",
    "        maxlen = input.size(0)\n",
    "        batch_size = input.size(1)\n",
    "\n",
    "        # Déplacement de l'entrée sur le bon device\n",
    "        input = input.to(self.device)\n",
    "        if lengths is not None:\n",
    "            lengths = lengths.to(self.device)\n",
    "\n",
    "        # Entrée vers embeddingts\n",
    "        xemb = self.emb(input).to(self.device)\n",
    "\n",
    "        # Passage dans le rec\n",
    "        hidden, last = self.rec(xemb)   # RNN\n",
    "\n",
    "        # Récupération des dernières couches\n",
    "        if lengths is not None:\n",
    "            last = torch.stack([hidden[lengths[i] - 1, i, :].to(self.device) for i in range(batch_size)])\n",
    "\n",
    "        # Ajout de l'attention\n",
    "        a = self.attention(hidden).squeeze(-1).to(self.device)\n",
    "\n",
    "        # Mask\n",
    "        mask = torch.arange(maxlen, device=self.device).unsqueeze(1).expand(maxlen, batch_size) < lengths.unsqueeze(0)\n",
    "        masked_attn_scores = a.masked_fill(~mask, float('-inf'))\n",
    "\n",
    "        # Calcul de l'attention (utilisation du softmax) + application sur les couches cachées\n",
    "        a = F.softmax(masked_attn_scores, dim=0).unsqueeze(-1)\n",
    "\n",
    "        last = torch.sum(a * hidden, dim=0)\n",
    "\n",
    "        output = self.h2o(last).squeeze(0)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66048f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "\n",
    "# Taille de la couche cachée\n",
    "n_hidden = 128\n",
    "output_size = 2\n",
    "\n",
    "# Réseau\n",
    "rnn = RNNSent( n_hidden,  output_size, embeddings, device)\n",
    "rnn.name = \"RNNSent-\"+time.asctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb100ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la métrique d'évaluation\n",
    "def accuracy(yhat,y):\n",
    "    assert len(y.shape)==1 or y.size(1)==1\n",
    "    return (torch.argmax(yhat,1).view(y.size(0),-1)== y.view(-1,1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boucle d'entraînement\n",
    "def train(model, epochs, train_loader, test_loader):\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1e-3)  # choix optimizer\n",
    "    model = model.to(device)\n",
    "    print(f\"running {model.name}\")\n",
    "    loss = nn.CrossEntropyLoss()  # choix loss\n",
    "\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        cumloss, cumacc, count = 0, 0, 0\n",
    "        model.train()\n",
    "        for x, lengths, y in train_loader:  # boucle sur les batchs\n",
    "            optim.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)  # y doit être un tenseur (pas un int)\n",
    "            yhat, next_hidden = model(x, lengths)\n",
    "            l = loss(yhat, y)\n",
    "            l.backward()\n",
    "            optim.step()\n",
    "            cumloss += l * len(x)  # attention, il peut y avoir un batch + petit (le dernier)\n",
    "            cumacc += accuracy(yhat, y) * len(x)\n",
    "            count += len(x)\n",
    "        print(epoch)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            cumloss, cumacc, count = 0, 0, 0\n",
    "            for x, lengths, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                yhat, next_hidden = model(x, lengths)\n",
    "                cumloss += loss(yhat, y) * len(x)\n",
    "                cumacc += accuracy(yhat, y) * len(x)\n",
    "                count += len(x)\n",
    "\n",
    "            # Calcul des performances de test\n",
    "            test_loss = cumloss / count\n",
    "            test_acc = cumacc / count\n",
    "            test_losses.append(test_loss.item())\n",
    "            test_accuracies.append(test_acc.item()*100)\n",
    "            print(f\"Epoch {epoch}: Test Loss = {test_loss:.4f}, Test Accuracy = {test_acc*100:.4f}%\")\n",
    "\n",
    "    return model, test_losses, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51c8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "mod, test_l, test_a = train(rnn, n_epoch, train_loader, test_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9400333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé des courbes\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Courbe de la loss\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.plot(test_l, label='Test Loss', color='orange')\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Courbe de l'accuracy\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.plot(test_a, label='Test Accuracy', color='green')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Légende et affichage\n",
    "fig.tight_layout()\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "plt.title('Training Loss and Test Accuracy - Deep Learning')\n",
    "plt.show()\n",
    "\n",
    "print('Meilleure accuracy : ', max(test_a), '%')\n",
    "\n",
    "global_result.append(max(test_a))\n",
    "global_methode.append('Deep Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec155e",
   "metadata": {},
   "source": [
    "![Training Loss and Test Loss - Deep Learning](images/deep.png)\n",
    "\n",
    "Les performances brutes sont globalement moins bonnes qu'une approche plus simple de BoW. Nous pouvons, là encore, mener avec optuna une campagne d'optimisation des hyperparamètres. Seront explorés :\n",
    "- la taille de la couche cachée\n",
    "- le taux d'apprentissage\n",
    "- la taille de batch\n",
    "- le nombre d'epoch d'apprentissage\n",
    "- l'optimiseur\n",
    "- une régularisation L2\n",
    "- le dropout\n",
    "\n",
    "Attention : cette campagne est <b>extrêmement longue</b> à exécuter ! Il aura fallu plus de 16 heures sur un petit gpu cuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f4a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libération de la mémoire\n",
    "def free_up_memory():\n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Fonction d'objectif pour Optuna\n",
    "def objective(trial):\n",
    "    # Suggestion des hyperparamètres\n",
    "    hidden_size = trial.suggest_int('hidden_size', 32, 512)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32])\n",
    "    epochs = trial.suggest_int('epochs', 1, 15)\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD', 'RMSprop'])\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
    "    dropout = trial.suggest_uniform('dropout', 0.2, 0.5)\n",
    "\n",
    "    # Initialisation du modèle\n",
    "    model = RNNSent(hidden_size, output_size, embeddings, device)\n",
    "    model.name = \"RNNSent-Optuna\"\n",
    "\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer_name == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    else:\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # DataLoader avec la taille de batch spécifiée\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # Entraînement et évaluation\n",
    "    model, test_losses, test_accuracies = train(model, epochs, train_loader, test_loader)\n",
    "\n",
    "    # Libération de la mémoire après l'entraînement\n",
    "    free_up_memory()\n",
    "\n",
    "    # Retourne la meilleure accuracy de test\n",
    "    best_accuracy = max(test_accuracies)\n",
    "    return best_accuracy\n",
    "\n",
    "# Création de l'étude Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50, callbacks=[lambda study, trial: free_up_memory()])\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "global_result.append(format(trial.value))\n",
    "global_methode.append('Deep Learning - Optimisé')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8d71a",
   "metadata": {},
   "source": [
    "Best trial:\n",
    "\n",
    "    Value: 80.74683547019958\n",
    "  \n",
    "  Params: \n",
    "    \n",
    "    hidden_size: 39\n",
    "    learning_rate: 1.127222730772094e-05  \n",
    "    batch_size: 32\n",
    "    num_epochs: 15\n",
    "    optimizer: SGD\n",
    "    weigh_decay: 7.095839077194373e-05\n",
    "    dropout: 0.2168193597137401"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d2ec67",
   "metadata": {},
   "source": [
    "L'optimisation permet d'améliorer les performances par rapport à la version simpliste. Toutefois, nous ne dépassons pas le BoW avec prétraitement, malgrès ce à quoi l'on pourrait s'attendre. En effet, les approches deep learning sont plus récentes et donc a priori plus performantes. Cette expérience nous montre que cela n'est pas systématique\n",
    "\n",
    "\n",
    "### Une approche originale : ollama et zero/few-shot\n",
    "\n",
    "Ollama est un projet permettant d'exécuter, sur un serveur virtuel local, des modèles de TAL open-source. Il existe une bibliothèque python permettant d'extraire les réponses issues de ce serveur et les utiliser dans une fonction. Nous allons utliser cela afin de mener une campagne de classification zero-shot et few-shot. Le modèle choisi ici est qwen 2.5 en taille 0,5b, présentant le meilleur compromis taille / qualité.\n",
    "\n",
    "#### Zero-shot\n",
    "La méthode <b>zero-shot</b> consiste à donner le texte à classifier au modèle et lui demander directement son \"avis\" dessus. Nous lui demandons ainsi directement de mener la recherche demandée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b9b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification zero-shot\n",
    "def classification_zero_shot(exemple):\n",
    "    prompt = f\"Give the sentiment of the following text in only one word: 'Positive' or 'Negative' :\\n\\n{exemple}\"\n",
    "    reponse = ollama.generate(model='qwen2.5:0.5b',prompt=prompt)\n",
    "    return reponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2018f",
   "metadata": {},
   "source": [
    "#### Few-shot\n",
    "Comme pour le zero-shot, le <b>few-shot</b> consiste à demander directement au modèle son avis. Toutefois, nous lui donnons, dans l'instruction, des exemples préalables afin de l'aider à mieux se repérer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification few-shot\n",
    "def classification_few_shot(exemple):\n",
    "    prompt = f\"These texts are in the category 'Positive': \\n{txts[1500]}\\n and \\n{txts[1700]}.\\n\\nThese texts are in the category 'Negative': \\n{txts[500]}\\n and \\n{txts[700]}.\\n\\n Give the sentiment of the following text in only one word: 'Positive' or 'Negative' :\\n\\n{exemple}\"\n",
    "    reponse = ollama.generate(model='qwen2.5:0.5b',prompt=prompt)\n",
    "    return reponse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b93547a",
   "metadata": {},
   "source": [
    "<b>Attention !</b> Ces deux méthodes sont très sensibes à l'instruction fournie (le prompt) ; changer l'instruction pourrait mener à de grandes différences de performances. De plus, il n'est pas possible de mettre en place une graine de génération aléatoire pour reproduire aisément les résultats. Les instructions fournies ont été déterminées à force d'essais et semble être les plus fonctionnelles. Enfin, les résultat sont très dépendants du modèle utilisé ; utiliser le dernier et plus performant modèle de raisonnement comme deepseek-r1 671b donnerai assurément de meilleurs résultats, mais avec un coût calculatoire bien plus important.\n",
    "\n",
    "#### Évaluation\n",
    "Nous allons comparer la réponse du modèle avec la catégorie effective du commentaire fourni. Nous ajoutons cependant une troisième catégorie, lorsque la réponse donnée n'est pas dans le format attendu. En effet, nous voulons obtenir \"Negative\" ou \"Positive\", mais il arrive que le modèle puisse répondre \"Negative.\", \"positive\", \"Positive \", \"This review is negative.\", etc. Nous considérons ces réponses commes invalides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8383a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_perf(dataset,methode,labels_vrais):\n",
    "    # Mélange des données\n",
    "    temp = list(zip(dataset, labels_vrais))\n",
    "    random.shuffle(temp)\n",
    "    dataset, labels_vrais = zip(*temp)\n",
    "    dataset, labels_vrais = list(dataset), list(labels_vrais)\n",
    "\n",
    "    ok,pb_rep,nul=0,0,0\n",
    "\n",
    "    pattern_positive = re.compile(r\"(?i)\\s*positive\\s*[\\W]*\")\n",
    "    pattern_negative = re.compile(r\"(?i)\\s*negative\\s*[\\W]*\")\n",
    "    \n",
    "    for k in range(len(dataset)):\n",
    "        response = methode(dataset[k]).response\n",
    "        if (pattern_positive.match(response) and labels_vrais[k]==1) or (pattern_negative.match(response) and labels_vrais[k]==0):\n",
    "            ok+=1\n",
    "        elif not pattern_positive.match(response) and not pattern_negative.match(response):\n",
    "            pb_rep+=1\n",
    "        else:\n",
    "            nul+=1\n",
    "    return ok, pb_rep, nul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7053fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy classification zero-shot\n",
    "o1,p1,n1 = test_perf(txts_test, classification_zero_shot, filelabels_test)\n",
    "\n",
    "perc_o1 = 100*o1/(len(txts_test))\n",
    "perc_p1 = 100*p1/(len(txts_test))\n",
    "perc_n1 = 100*n1/(len(txts_test))\n",
    "\n",
    "print(\n",
    "    'Zero-shot\\n Ok : ', perc_o1, '%\\n', \n",
    "    'Nuls : ', perc_n1, '%\\n', \n",
    "    'Mauvais format de réponse : ', perc_p1, '%.')\n",
    "\n",
    "global_result.append(perc_o1)\n",
    "global_methode.append('Ollama - zero-shot')\n",
    "\n",
    "# Accuracy classification few-shot\n",
    "o2,p2,n2 = test_perf(txts_test, classification_few_shot, filelabels_test)\n",
    "\n",
    "perc_o2 = 100*o2/(len(txts_test))\n",
    "perc_p2 = 100*p2/(len(txts_test))\n",
    "perc_n2 = 100*n2/(len(txts_test))\n",
    "\n",
    "print(\n",
    "    'Few-shot\\n Ok : ', perc_o2, '%\\n', \n",
    "    'Nuls : ', perc_n2, '%\\n', \n",
    "    'Mauvais format de réponse : ', perc_p2, '%.')\n",
    "\n",
    "global_result.append(perc_o2)\n",
    "global_methode.append('Ollama - few-shot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_o1=82.5\n",
    "perc_o2=78.5\n",
    "perc_n1=12.85\n",
    "perc_n2=16.95\n",
    "perc_p1=1.65\n",
    "perc_p2=4.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9902c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "X = ['Bonne \\n classification', 'Mauvaise \\n classification', 'Mauvais format \\n de réponse']\n",
    "\n",
    "zero_shot = [perc_o1, perc_n1, perc_p1]\n",
    "few_shot = [perc_o2, perc_n2, perc_p2]\n",
    "\n",
    "X_axis = np.arange(len(X)) \n",
    "  \n",
    "plt.bar(X_axis - 0.2, zero_shot, 0.4, label = 'zero shot') \n",
    "plt.bar(X_axis + 0.2, few_shot, 0.4, label = 'few shot') \n",
    "\n",
    "plt.xticks(X_axis, X) \n",
    "plt.legend() \n",
    "ax.set_ylabel('Accuracy (%)')\n",
    "ax.set_title(\"Taux de bonne classification, de mauvaise classification et de mauvais format de réponse \\n du modèle Qwen en zero-shot et few-shot\", pad = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e76d47",
   "metadata": {},
   "source": [
    "![Accuracy ollama](images/ollama1.png)\n",
    "Nous pourrions instinctivement s'attendre à ce que le few-shot soit plus efficace ; or, ça n'est pas systématiquement le cas. Cependant, comme expliqué précédemment, les résultats dépendent beaucoup de l'instruction et du modèle choisi, et varie même d'un essai à l'autre.\n",
    "Nous voyons également que, dans l'exemple fourni, le zero-shot nous offre les meilleures performances de tous les modèles explorés ici. Il est donc parfois plus simple de se reposer sur des modèles pré-entraînés.\n",
    "\n",
    "### Conclusion et récapitulatif\n",
    "\n",
    "Ce projet montre que les solutions les plus complexes ne sont pas forcément les meilleures. Le deep learning, approche la plus récente, se fait supplanter par des méthodes BoW et même de la classification Bayésienne naïve, quand bien même le TAL est une tâche où le deep learning est très performant. Il est donc important d'adapter la méthode à la complexité de la tâche : une classification binaire, comme celle-ci, ne demande pas de méthodes trop complexes.\n",
    "\n",
    "Le prétraitement des textes est une étape très importante pour améliorer les performances.\n",
    "\n",
    "Enfin, un modèle tout fait, même très léger (0.5 milliards de paramètres) peut supplanter toutes les approches \"maison\", comme nous avons pu le constater. Il va être très important de maîtriser leur usage afin de profiter de leurs capacités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cddec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme récapitulatif\n",
    "\n",
    "# Couleur selon la performance\n",
    "valeurs_normalisees = (np.array(global_result) - min(global_result)) / (max(global_result) - min(global_result))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(global_methode, global_result, color=plt.cm.RdYlGn(valeurs_normalisees))\n",
    "\n",
    "plt.title(\"Accuracy selon la méthode\")\n",
    "plt.xlabel(\"Méthode\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "\n",
    "# Affichage des valeurs sur les barres\n",
    "for i, v in enumerate(global_result):\n",
    "    plt.text(i, v + 0.5, str(v), ha='center', va='bottom')\n",
    "    \n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe04671",
   "metadata": {},
   "source": [
    "![Résumé des performances](images/resume2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
